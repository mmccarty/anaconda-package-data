{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anaconda Package Download Data\n",
    "\n",
    "This notebook demonstrates how to load and use Anaconda package data.  For more details, see the [Github repository](https://github.com/ContinuumIO/anaconda-package-data/blob/master/README.md).  Due to limitations on Binder, you might find some of the analysis examples below run slowly or require more memory than is available on the Binder instance.  Feel free to download this notebook locally and run it.\n",
    "\n",
    "\n",
    "## Setting up\n",
    "\n",
    "To start we need to install the needed packages by running `conda install dask intake numpy pandas` and `conda install -c conda-forge hvplot`. Then we can import the packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from datetime import datetime\n",
    "import hvplot.pandas\n",
    "import intake\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This enables the Dask progress bar on all operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.diagnostics import ProgressBar\n",
    "pbar = ProgressBar()\n",
    "pbar.register()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "There are multiple ways to load Anaconda package data. Below we show examples of loading one month of data for December 2018.\n",
    "\n",
    "#### Method 1:  load data from S3 url\n",
    "\n",
    "First, we can read parquet files directly from S3 url. We recommend using `dask.dataframe` to read data files into a Dask DataFrame. Please visit the [Dask website](http://docs.dask.org/en/latest/dataframe.html) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = dd.read_parquet('s3://anaconda-package-data/conda/hourly/2019/*/*.parquet',\n",
    "#                     storage_options={'anon': True})\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: load data from intake catalog\n",
    "Second, we can load data from an Intake catalog file. One advantage of using intake catalog is that we can define the cache specifications in the catelog so that intake caches remote data source files locally. This saves bandwidth and improves the performance of future analyses. If you would like to remove the intake cache, simply run intake cache clear. For more information on Intake catalogs, click here.\n",
    "\n",
    "Before loading the data file, we need to load the Intake catalog file. We can use a URL to the catalog file directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = intake.open_catalog('https://raw.githubusercontent.com/ContinuumIO/anaconda-package-data/master/catalog/anaconda_package_data.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can load the data with user specified year and month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cat.anaconda_package_data_by_year(year=2019).to_dask()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, if you would like to read data directly into a Pandas Dataframe, please use `intake.cat.anaconda_package_data_by_month(year=2018, month=12).read()`.\n",
    "\n",
    "## Examples\n",
    "\n",
    "After loading the data, we can do a lot of data wrangling and visualization to answer interesting questions. Below we show a few examples of how people can use the data. \n",
    "\n",
    "#### Example 1: Dask download statistics\n",
    "\n",
    "In this first example, we are looking at the download statistics of Dask. First, let's see how many times Dask is installed this year from Anaconda distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkg_names = ['dask', 'ray', 'koalas']\n",
    "#df.loc[(df.data_source=='anaconda') & df.pkg_name==pkg_name)]['counts'].sum().compute()\n",
    "\n",
    "pkg_counts = [{pkg_name: df.loc[df.pkg_name == pkg_name]['counts'].sum()} \n",
    "              for pkg_name in pkg_names]\n",
    "dask.compute(pkg_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `.compute()` is needed when df is a dask dataframe. Delete `.compute()` if you load data into a pandas dataframe. Please visit [dask website](http://docs.dask.org/en/latest/dataframe.html) for more information.\n",
    "\n",
    "Next, let's take a look at the daily trends of pandas usage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = df.time.dt.month\n",
    "pkg_month_agg = df\\\n",
    "    .loc[(df.pkg_name == 'dask') | (df.pkg_name == 'ray') | (df.pkg_name == 'koalas')]\\\n",
    "    .groupby(['month', 'pkg_name'])\\\n",
    "    .sum()\\\n",
    "    .reset_index()\\\n",
    "    .compute()\n",
    "pkg_month_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkg_month_agg.hvplot.bar('month','counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = hv.Dataset(pkg_month_agg, ['month', 'pkg_name'], 'counts')\n",
    "bars = ds.to(hv.Bars, ['month', 'pkg_name'], 'counts')\n",
    "bars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2: Package platform comparison\n",
    "\n",
    "We can also compare package platforms. Here we calculated the total number of downloads from each platform and visualize the results in a bar chart.  (Note that \"noarch\" packages have no platform value because they work on all platforms.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform_month = df\\\n",
    "    .loc[(df.pkg_name == 'dask') | (df.pkg_name == 'ray') | (df.pkg_name == 'koalas')]\\\n",
    "    .groupby(['pkg_platform'])['counts'].sum().reset_index().compute()\n",
    "platform_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform_month.hvplot.bar('pkg_platform', 'counts', rot=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
